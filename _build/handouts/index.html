<!DOCTYPE html>
<html lang="en">
  <head>
      <meta charset="utf-8" />
      <meta name="viewport" content="width=device-width, initial-scale=1" />
      <title>Capstone Test Plans | Devmountain Foundations</title>

      <link
        href="_static/pygments.css"
        rel="stylesheet"
        type="text/css"
      />
      <link href="_static/devmountain.css" rel="stylesheet" type="text/css" />
          <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
          <link rel="stylesheet" type="text/css" href="_static/devmountain.css" />
          <link rel="stylesheet" type="text/css" href="_static/plot_directive.css" />
          <link rel="stylesheet" type="text/css" href="_static/graphviz.css" />

      <script src="_static/pdfobject.min.js"></script>
      
  </head>
  <body>
      <div id="handouts-container">
        <header id="page-header">
            <p id="project-title">Devmountain Foundations</p>
            <p id="page-title">Capstone Test Plans</p>
              <p id="backlink">
                <a href="/"> &laquo; Back to Homepage </a>
              </p>
        </header>

        <nav id="page-toc"><ul>
<li><a class="reference internal" href="#">Capstone Test Plans</a><ul>
<li><a class="reference internal" href="#introduction-welcome-to-the-project-phase">Introduction: Welcome to the Project Phase!</a></li>
<li><a class="reference internal" href="#draft-your-test-plan">Draft Your Test Plan</a></li>
<li><a class="reference internal" href="#outline-a-to-do-list">Outline a To Do List</a></li>
<li><a class="reference internal" href="#review">Review</a></li>
<li><a class="reference internal" href="#do-not-skip">Do Not Skip</a></li>
<li><a class="reference internal" href="#rubric">Rubric</a></li>
</ul>
</li>
</ul>
</nav>

        <main id="page-content">
            <section class="section" id="capstone-test-plans">
<h1>Capstone Test Plans</h1>
<section class="section" id="introduction-welcome-to-the-project-phase">
<h2>Introduction: Welcome to the Project Phase!</h2>
<p>Previously, you prepared to begin your project by finding websites to test,
finding selectors, and listing the major features of each site. Now, you’ve
made it to the first official day of working
on your project. Congrats! This is an exciting, yet overwhelming moment. It
can be easy to not know where to begin. Fortunately, the first step is
quite clear – you will be writing test plans.</p>
</section>
<section class="section" id="draft-your-test-plan">
<h2>Draft Your Test Plan</h2>
<ol class="arabic simple">
<li><p><strong>Create a Test Plan</strong>: In Trello (or similar) you should create your test plan.</p></li>
<li><p><strong>Determine Features to be Tested</strong>: Review the major features of the websites you’re testing. Add any features that you’ll be testing. Prioritizing these can be helpful. Smaller pieces are individually much easier to accomplish.</p></li>
<li><p><strong>Document Features not to be Tested</strong>: If you know you won’t test something, list it, and your reasoning.</p></li>
<li><p><strong>Outline Testing</strong>: Having an idea of how you will test each area of functionality is quite helpful. Test cases can be good, even if you’re just defining placeholders for now; they can keep you on track.</p></li>
</ol>
<div class="admonition note">
<p class="admonition-title">Utilize the Rubric</p>
<div class="admonition-body docutils container">
<p>Make sure to read over the rubric as well. It is included at the bottom of these instructions and should help you with your planning.</p>
</div>
</div>
</section>
<section class="section" id="outline-a-to-do-list">
<h2>Outline a To Do List</h2>
<p>With a loose test plan, you should determine the tasks that need to be done to accomplish your testing. These tasks can be tracked in Trello as tasks that you can pick up and work on when it’s time.</p>
<p>The following tasks will probably exist in every project; note that some of these bullet points would represent multiple tasks:</p>
<ul class="simple">
<li><p>Create a public GitHub repository</p></li>
<li><p>Create required page objects</p></li>
<li><p>With appropriate selectors</p></li>
<li><p>With abstracted functionality</p></li>
<li><p>Check for API requests that can be reproduced in Postman</p></li>
<li><p>Plan ahead for iterable tests</p></li>
<li><p>Determine needed test data</p></li>
</ul>
</section>
<section class="section" id="review">
<h2>Review</h2>
<ol class="arabic simple">
<li><p>Take a small break and look back over your tasks. Are you missing anything? Do you need to break anything down?</p></li>
<li><p>Clean it up as you can! A lot of it will happen naturally as you go along.</p></li>
<li><p>Set priorities - you should always know what you have to work on next.</p></li>
</ol>
</section>
<section class="section" id="do-not-skip">
<h2>Do Not Skip</h2>
<div class="admonition warning">
<p class="admonition-title">Approval is required</p>
<div class="admonition-body docutils container">
<p>In order to properly finish this exercise, you need to obtain approval
by a staff member. You will need to pass your test plans off with them.
Hop in the queue when you are ready to have your plan reviewed.</p>
</div>
</div>
</section>
<section class="section" id="rubric">
<h2>Rubric</h2>
<p>The following rubric details the requirements for this project. There are 36 points possible, and 26 points are required to pass.</p>
<p><strong>Passing Score</strong>: 26/36</p>
<table class="colwidths-given docutils align-default" style="width: 150%">
<colgroup>
<col style="width: 10%" />
<col style="width: 20%" />
<col style="width: 10%" />
<col style="width: 20%" />
<col style="width: 20%" />
<col style="width: 20%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Section</p></th>
<th class="head"><p>Detail</p></th>
<th class="head"><p>0 Points</p></th>
<th class="head"><p>1 Point</p></th>
<th class="head"><p>2 Points</p></th>
<th class="head"><p>3 Points</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Test Plan</p></td>
<td><p>You must have submitted a good test plan, with each of the following documented:
1) What is being tested.
2) How testing will be accomplished.
3) Risks to look out for.
4) Links to automation, and other related assets.</p></td>
<td><p>Not attempted</p></td>
<td><p>The test plan is unclear, or lacking required content.</p></td>
<td><p>Required elements are all present in the test plan, and it is adequately clear.</p></td>
<td><p>The test plan has been extremely well maintained with links to test cases, documentation, automation, etc. Changes are well described, and the test summary report is well documented.</p></td>
</tr>
<tr class="row-odd"><td><p>Tests</p></td>
<td><p>Your project tests 2 different websites and includes 10 or more tests for each website (at least 20 total).</p></td>
<td><p>Not attempted</p></td>
<td><p>The project includes fewer than 10 tests or only tests one website.</p></td>
<td><p>The project tests 2 websites but has fewer than 20 tests total.</p></td>
<td><p>The project tests 2 websites, with at least 10 tests per website.</p></td>
</tr>
<tr class="row-even"><td><p>Manual Tests</p></td>
<td><p>Your tests, whether broad or detailed, should cover the criteria covered by your test plan, and show good utilization of test design techniques.</p></td>
<td><p>Not attempted</p></td>
<td><p>You have not created enough test cases, or those you have do not include enough direction, and/or don’t include examples of each test design technique.</p></td>
<td><p>Your tests sufficiently cover the needs of the application. Each major test design technique is used at least once.</p></td>
<td><p>Your tests are thorough enough to cover the requirements and user experience, and have been tracked appropriately using the test execution subtasks. They also show excellent application of test design techniques.</p></td>
</tr>
<tr class="row-odd"><td><p>Automated Tests</p></td>
<td><p>The tests you have automated should test the application effectively.</p></td>
<td><p>Not attempted</p></td>
<td><p>The automated tests do not cover even basic functionality of the features to be tested, or do not make sense.</p></td>
<td><p>The automated test cases cover customer “happy” paths through the features to be tested.</p></td>
<td><p>The automated tests thoroughly check the test criteria set out for the features to be tested.</p></td>
</tr>
<tr class="row-even"><td><p>Soft Skills</p></td>
<td><p>You must show effective soft skills in your documentation, such that a newcomer could understand your efforts by browsing your test plan, tests, etc.</p></td>
<td><p>Not attempted</p></td>
<td><p>Your documentation leaves room for far too many questions.</p></td>
<td><p>Your testing efforts are sufficiently clear and understandable based solely on your documentation.</p></td>
<td><p>Your documentation is clear, your tests well named, and even your variables and methods are well names in your automation to make things clearer.</p></td>
</tr>
<tr class="row-odd"><td><p>Collaboration</p></td>
<td><p>You used source control tools and comments effectively to set yourself up for success on future projects.</p></td>
<td><p>Not attempted</p></td>
<td><p>Your code lacks sufficient comments and/or you did not use branching or pull requests to control your code contributions.</p></td>
<td><p>Your code is sufficiently commented, and you used branches and pull requests to control your code contributions.</p></td>
<td><p>Your comments make your code contributions simple to understand and use, and you used branches and pull requests extremely well.</p></td>
</tr>
<tr class="row-even"><td><p>Abstraction</p></td>
<td><p>You must leverage abstraction well in your automation, specifically using page objects and data files.</p></td>
<td><p>Not attempted</p></td>
<td><p>You are lacking abstraction like page objects or data files in your contributions.</p></td>
<td><p>You have organized your automation with page objects that have methods, as well as data files to contain test data.</p></td>
<td><p>Your code is well organized with effective methods in your page objects that will limit maintenance costs and efforts to add additional tests. Your data files are well conceived and easy to update as well.</p></td>
</tr>
<tr class="row-odd"><td><p>Reliable Execution</p></td>
<td><p>Your automation should be stable enough to run on different machines/internet connections.</p></td>
<td><p>Not attempted</p></td>
<td><p>Your automation does not run reliably, failing due to differences in internet connections or devices.</p></td>
<td><p>Your automation is adequately stable.</p></td>
<td><p>The automation is extremely stable, using waits and other methods to cleanly handle different systems.</p></td>
</tr>
<tr class="row-even"><td><p>Reliable Results</p></td>
<td><p>Your automation should assert on the right things, producing effective results rather than false positives/negatives.</p></td>
<td><p>Not attempted</p></td>
<td><p>You are not asserting on the right criteria to test your functionality, and/or you have a number of false positives in your tests.</p></td>
<td><p>The assertions in your tests are sufficient to identify whether the feature you are testing is working.</p></td>
<td><p>Not only do the assertions look at the right conditions, but your code is well structured to avoid false positives.</p></td>
</tr>
<tr class="row-odd"><td><p>Reliable Iteration</p></td>
<td><p>You have examples of effective iteration in your automation, running the same tests with different data.</p></td>
<td><p>Not attempted</p></td>
<td><p>Your automation lacks iteration.</p></td>
<td><p>You step through test data to check different combinations of inputs and expected outputs.</p></td>
<td><p>Your iteration is clear, stepping through data imported from data objects and creating a new test for each iteration.</p></td>
</tr>
<tr class="row-even"><td><p>API Testing</p></td>
<td><p>Wherever possible, you should attempt to recreate API requests that your application uses. (Identified through DevTools: Network Tab)</p></td>
<td><p>Not attempted</p></td>
<td><p>You did not document any attempts at using the API, or your notes were insufficient.</p></td>
<td><p>You made a good attempt at testing the API and included notes about your attempts and their results in your test plan/test cases, along with any applicable documetnation/Postman exports.</p></td>
<td><p>You were able to execute one or more API requests and used Postman/Newman to test that endpoint well, including the exported request/tests in your GitHub repository, and great comments in the test plan.</p></td>
</tr>
<tr class="row-odd"><td><p>Reports</p></td>
<td><p>You report your progress in a number of ways, but for this project, sufficient bug reports need to be created, and your test summary report should cover your thoughts throughout the process. Visuals are encouraged.</p></td>
<td><p>Not attempted</p></td>
<td><p>You have not reported enough major problems, or have not included enough detail to reproduce issues, and/or your report is missing or incomplete.</p></td>
<td><p>Your bug reports at least cover the most important problems present in the application with enough detail to reproduce the problems. Your report is sufficient to share key updates.</p></td>
<td><p>You have excellent bug reports with great attention to detail, as well as a thorough test summary report that will let any reader understand how testing has gone.</p></td>
</tr>
</tbody>
</table>
</section>
</section>

        </main>

        <footer id="page-footer">
            <p>&copy; 2022 Devmountain</p>
        </footer>
      </div>

      <script src="_static/main.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
  </body>
</html>